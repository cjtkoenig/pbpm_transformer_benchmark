# Global defaults you can override from CLI, e.g.:
# python -m src.cli task=next_activity model.hidden_size=512
seed: 42

task: next_activity            # next_activity | suffix | next_time | remaining_time | multi_task
cv:
  n_folds: 5
  stratify: null
  split_by_cases: true

data:
  path_raw: data/raw
  path_processed: data/processed
  end_of_case_token: "<eoc>"
  max_prefix_length: null
  attribute_mode: minimal      # minimal | extended
  datasets: ["BPI_Challenge_2012", "BPI_Challenge_2019", "Helpdesk", "Road_Traffic_Fine_Management_Process", "Sepsis Cases - Event Log", "Tourism"]   # Referenzdatens√§tze + Tourismus

model:
  name: process_transformer  # process_transformer (and future transformer models)
  max_case_length: 50
  embed_dim: 36
  num_heads: 4
  ff_dim: 64

train:
  batch_size: 128
  max_epochs: 10
  learning_rate: 3e-4
  accelerator: auto            # auto | cpu | gpu | mps
  devices: 1

metrics:
  next_activity: ["accuracy", "f1_score"]
  suffix: ["normalized_damerau_levenshtein"]
  time: ["mae", "rmse", "r2"]

# Preprocessing management (optional)
preprocess_action: null        # info | clear | force
dataset_name: null             # For clearing specific dataset
force_preprocess: false        # Force reprocessing even if processed data exists